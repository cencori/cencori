---
title: "Core Architecture"
description: "Understand the fundamental concepts behind the Cencori platform: CIP, Data Residency, and Global Infrastructure."
section: "Concepts"
order: 1
---

## Cloud Intelligence Provider (CIP)

Cencori is not just an "AI Proxy." We are a **Cloud Intelligence Provider (CIP)**.

- **AI Proxy**: A simple pass-through layer that forwards requests. (e.g., Cloudflare AI Gateway).
- **CIP**: A fully managed infrastructure layer that provides **stateful** intelligence. Cencori maintains context (Memory), enforces security (Scan), and orchestrates multi-step logic (Workflows) *before* requests ever reach a model provider.

## Request Lifecycle

Understanding the flow of a single request helps clarify where value is added:

1.  **Application**: Your code calls the Cencori SDK.
2.  **Edge Network**: Request hits the nearest Cencori Edge node (deployed globally across 35+ regions).
3.  **Security Scan**: Payload is analyzed for PII, prompt injection, and policy violations. *Latency: &lt;10ms*.
4.  **Routing Engine**: Cencori determines the optimal provider based on cost, status, and your project rules.
5.  **Provider Execution**: Request is forwarded to OpenAI/Anthropic/Google.
6.  **Observability**: Response is logged, token usage is calculated, and async evals are triggered.
7.  **Response**: Final payload is returned to your application.

> **Cold Starts**: Cencori's edge network is built on warm execution environments. There is **zero cold-start latency** for standard API requests.

## Data Residency & Privacy

We take data sovereignty seriously.

- **Logs & Analytics**: Stored in our secure US-East (N. Virginia) cluster by default. Enterprise plans support EU-only storage.
- **AI Memory (Vector Store)**: Embeddings and vector data are encrypted at rest in dedicated isolated clusters.
- **Ephemeral Processing**: Determining PII or routing logic happens in-memory on edge nodes and is never persisted to disk.

## Global Infrastructure

Cencori is multi-cloud and multi-region by default.

- **Availability**: 99.99% uptime SLA for Enterprise.
- **Regions**: We route traffic through AWS, GCP, and Cloudflare networks to ensure lowest-latency connectivity to AI providers.
- **Failover**: If a region goes down, traffic is automatically re-routed to the next nearest healthy node.

## Platform Limits

To ensure fair usage and stability, the following limits apply:

| Limit | Free Tier | Pro Plan | Enterprise |
|-------|-----------|----------|------------|
| **Concurrent Requests** | 10 | 100 | Unlimited |
| **Requests per Month** | 10k | 1M | Custom |
| **Log Retention** | 3 Days | 30 Days | 90+ Days |
| **Team Members** | 1 | 5 | Unlimited |

## Keys & Authentication

- **Project Keys (`csk_...`)**: Scoped to a specific project. Used by your application SDKs. If compromised, only that single project is affected.
- **Organization Keys** (Coming Soon): Admin-level keys for programmatic management of multiple projects.

## Comparison

Why choose Cencori over other solutions?

| Feature | Cencori (CIP) | Helicone / Portkey | LangChain / LangSmith |
|---------|---------------|-------------------|-----------------------|
| **Primary Goal** | Production Infrastructure | Observability & Logging | Prototyping Framework |
| **Security (PII/Injection)** | **Native / Built-in** | Plugin / External | Manual Implementation |
| **Unified SDK** | **Yes (One API)** | No (Proxy only) | Yes (Abstractions) |
| **Multi-Provider** | **Native** | Native | Native |
| **Vector Memory** | **Integrated** | No | External (Vector DB) |
| **Latency Impact** | **< 15ms** | ~50-100ms | N/A (Client-side) |

## Glossary

- **Gateway**: The unified entry point for all AI requests.
- **Memory**: Cencori's managed vector store for RAG and long-term history.
- **Scan**: The security engine that inspects requests for vulnerabilities.
- **Namespace**: A logical partition within Memory to isolate data (e.g., per-user or per-document).
