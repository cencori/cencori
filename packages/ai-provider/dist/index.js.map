{"version":3,"sources":["../src/index.ts","../src/cencori-chat-model.ts","../src/cencori-provider.ts"],"sourcesContent":["/**\n * Cencori AI Provider for Vercel AI SDK\n * \n * @example\n * import { cencori } from '@cencori/ai-provider';\n * import { streamText } from 'ai';\n * \n * const result = await streamText({\n *   model: cencori('gemini-2.5-flash'),\n *   messages: [{ role: 'user', content: 'Hello!' }]\n * });\n */\n\nexport { cencori, createCencori } from './cencori-provider';\nexport type { CencoriProvider } from './cencori-provider';\nexport type { CencoriProviderSettings, CencoriChatSettings } from './types';\nexport { CencoriChatLanguageModel } from './cencori-chat-model';\n","/**\n * Cencori Chat Language Model\n * \n * Implements the Vercel AI SDK's LanguageModelV1 interface\n */\n\nimport type {\n    LanguageModelV1,\n    LanguageModelV1CallOptions,\n    LanguageModelV1CallWarning,\n    LanguageModelV1FinishReason,\n    LanguageModelV1FunctionToolCall,\n    LanguageModelV1LogProbs,\n    LanguageModelV1ProviderMetadata,\n    LanguageModelV1StreamPart,\n} from '@ai-sdk/provider';\n\nexport interface CencoriChatModelSettings {\n    apiKey: string;\n    baseUrl: string;\n    headers?: Record<string, string>;\n    userId?: string;\n}\n\ninterface CencoriMessage {\n    role: 'system' | 'user' | 'assistant';\n    content: string;\n}\n\ninterface CencoriResponse {\n    content: string;\n    model: string;\n    provider: string;\n    usage: {\n        prompt_tokens: number;\n        completion_tokens: number;\n        total_tokens: number;\n    };\n    cost_usd: number;\n    finish_reason?: string;\n}\n\ninterface CencoriStreamChunk {\n    delta: string;\n    finish_reason?: string;\n}\n\nexport class CencoriChatLanguageModel implements LanguageModelV1 {\n    readonly specificationVersion = 'v1' as const;\n    readonly provider = 'cencori';\n    readonly defaultObjectGenerationMode = 'json' as const;\n    readonly supportsImageUrls = false;\n\n    readonly modelId: string;\n    private readonly settings: CencoriChatModelSettings;\n\n    constructor(modelId: string, settings: CencoriChatModelSettings) {\n        this.modelId = modelId;\n        this.settings = settings;\n    }\n\n    private getHeaders(): Record<string, string> {\n        return {\n            'Content-Type': 'application/json',\n            'CENCORI_API_KEY': this.settings.apiKey,\n            ...this.settings.headers,\n        };\n    }\n\n    private convertMessages(options: LanguageModelV1CallOptions): CencoriMessage[] {\n        const messages: CencoriMessage[] = [];\n\n        // Handle system prompt\n        if (options.prompt && typeof options.prompt === 'object' && 'system' in options.prompt && options.prompt.system) {\n            messages.push({ role: 'system', content: options.prompt.system as string });\n        }\n\n        // Convert AI SDK messages to Cencori format\n        if (options.prompt && typeof options.prompt === 'object' && 'messages' in options.prompt) {\n            const promptMessages = options.prompt.messages as Array<{\n                role: string;\n                content: unknown;\n            }>;\n\n            for (const msg of promptMessages) {\n                let content = '';\n\n                if (typeof msg.content === 'string') {\n                    content = msg.content;\n                } else if (Array.isArray(msg.content)) {\n                    // Handle multipart messages (text + images)\n                    content = msg.content\n                        .filter((part: { type: string }) => part.type === 'text')\n                        .map((part: { type: string; text?: string }) => part.text || '')\n                        .join('');\n                }\n\n                if (content) {\n                    messages.push({\n                        role: msg.role as 'system' | 'user' | 'assistant',\n                        content,\n                    });\n                }\n            }\n        }\n\n        return messages;\n    }\n\n    private mapFinishReason(reason?: string): LanguageModelV1FinishReason {\n        switch (reason) {\n            case 'stop':\n            case 'end_turn':\n                return 'stop';\n            case 'length':\n            case 'max_tokens':\n                return 'length';\n            case 'content_filter':\n                return 'content-filter';\n            case 'tool_calls':\n            case 'tool-calls':\n                return 'tool-calls';\n            default:\n                return 'stop';\n        }\n    }\n\n    async doGenerate(options: LanguageModelV1CallOptions): Promise<{\n        text?: string;\n        toolCalls?: LanguageModelV1FunctionToolCall[];\n        finishReason: LanguageModelV1FinishReason;\n        usage: { promptTokens: number; completionTokens: number };\n        rawCall: { rawPrompt: unknown; rawSettings: Record<string, unknown> };\n        rawResponse?: { headers?: Record<string, string> };\n        warnings?: LanguageModelV1CallWarning[];\n        logprobs?: LanguageModelV1LogProbs;\n        providerMetadata?: LanguageModelV1ProviderMetadata;\n    }> {\n        const messages = this.convertMessages(options);\n\n        const response = await fetch(`${this.settings.baseUrl}/api/ai/chat`, {\n            method: 'POST',\n            headers: this.getHeaders(),\n            body: JSON.stringify({\n                messages,\n                model: this.modelId,\n                temperature: options.temperature,\n                maxTokens: options.maxTokens,\n                stream: false,\n                userId: this.settings.userId,\n            }),\n            signal: options.abortSignal,\n        });\n\n        if (!response.ok) {\n            const error = await response.json().catch(() => ({ error: 'Unknown error' })) as { error?: string };\n            throw new Error(`Cencori API error: ${error.error || response.statusText}`);\n        }\n\n        const data = await response.json() as CencoriResponse;\n\n        return {\n            text: data.content,\n            finishReason: this.mapFinishReason(data.finish_reason),\n            usage: {\n                promptTokens: data.usage.prompt_tokens,\n                completionTokens: data.usage.completion_tokens,\n            },\n            rawCall: {\n                rawPrompt: messages,\n                rawSettings: {\n                    model: this.modelId,\n                    temperature: options.temperature,\n                    maxTokens: options.maxTokens,\n                },\n            },\n        };\n    }\n\n    async doStream(options: LanguageModelV1CallOptions): Promise<{\n        stream: ReadableStream<LanguageModelV1StreamPart>;\n        rawCall: { rawPrompt: unknown; rawSettings: Record<string, unknown> };\n        rawResponse?: { headers?: Record<string, string> };\n        warnings?: LanguageModelV1CallWarning[];\n    }> {\n        const messages = this.convertMessages(options);\n\n        const response = await fetch(`${this.settings.baseUrl}/api/ai/chat`, {\n            method: 'POST',\n            headers: this.getHeaders(),\n            body: JSON.stringify({\n                messages,\n                model: this.modelId,\n                temperature: options.temperature,\n                maxTokens: options.maxTokens,\n                stream: true,\n                userId: this.settings.userId,\n            }),\n            signal: options.abortSignal,\n        });\n\n        if (!response.ok) {\n            const error = await response.json().catch(() => ({ error: 'Unknown error' })) as { error?: string };\n            throw new Error(`Cencori API error: ${error.error || response.statusText}`);\n        }\n\n        const reader = response.body?.getReader();\n        if (!reader) {\n            throw new Error('Response body is null');\n        }\n\n        const decoder = new TextDecoder();\n        let buffer = '';\n        let promptTokens = 0;\n        let completionTokens = 0;\n\n        const stream = new ReadableStream<LanguageModelV1StreamPart>({\n            async pull(controller) {\n                try {\n                    const { done, value } = await reader.read();\n\n                    if (done) {\n                        // Send final usage and finish\n                        controller.enqueue({\n                            type: 'finish',\n                            finishReason: 'stop',\n                            usage: { promptTokens, completionTokens },\n                        });\n                        controller.close();\n                        return;\n                    }\n\n                    buffer += decoder.decode(value, { stream: true });\n                    const lines = buffer.split('\\n');\n                    buffer = lines.pop() || '';\n\n                    for (const line of lines) {\n                        if (line.trim() === '') continue;\n                        if (!line.startsWith('data: ')) continue;\n\n                        const data = line.slice(6);\n                        if (data === '[DONE]') {\n                            controller.enqueue({\n                                type: 'finish',\n                                finishReason: 'stop',\n                                usage: { promptTokens, completionTokens },\n                            });\n                            controller.close();\n                            return;\n                        }\n\n                        try {\n                            const chunk = JSON.parse(data) as CencoriStreamChunk;\n\n                            if (chunk.delta) {\n                                completionTokens += Math.ceil(chunk.delta.length / 4); // Rough estimate\n                                controller.enqueue({\n                                    type: 'text-delta',\n                                    textDelta: chunk.delta,\n                                });\n                            }\n\n                            if (chunk.finish_reason) {\n                                controller.enqueue({\n                                    type: 'finish',\n                                    finishReason: 'stop',\n                                    usage: { promptTokens, completionTokens },\n                                });\n                                controller.close();\n                                return;\n                            }\n                        } catch {\n                            // Skip malformed JSON\n                        }\n                    }\n                } catch (error) {\n                    controller.error(error);\n                }\n            },\n            cancel() {\n                reader.cancel();\n            },\n        });\n\n        return {\n            stream,\n            rawCall: {\n                rawPrompt: messages,\n                rawSettings: {\n                    model: this.modelId,\n                    temperature: options.temperature,\n                    maxTokens: options.maxTokens,\n                },\n            },\n        };\n    }\n}\n","/**\n * Cencori AI Provider for Vercel AI SDK\n * \n * Use Cencori with streamText(), generateText(), and useChat()\n */\n\nimport { CencoriChatLanguageModel } from './cencori-chat-model';\nimport type { CencoriProviderSettings, CencoriChatSettings } from './types';\n\nexport interface CencoriProvider {\n    /**\n     * Create a Cencori chat model for use with Vercel AI SDK\n     * \n     * @param modelId - The model ID (e.g., 'gemini-2.5-flash', 'gpt-4o', 'claude-3-opus')\n     * @param settings - Optional model-specific settings\n     * @returns A LanguageModelV1 compatible model\n     * \n     * @example\n     * import { cencori } from '@cencori/ai-provider';\n     * import { streamText } from 'ai';\n     * \n     * const result = await streamText({\n     *   model: cencori('gemini-2.5-flash'),\n     *   messages: [{ role: 'user', content: 'Hello!' }]\n     * });\n     */\n    (modelId: string, settings?: CencoriChatSettings): CencoriChatLanguageModel;\n\n    /**\n     * Create a chat model (alias for the provider function)\n     */\n    chat: (modelId: string, settings?: CencoriChatSettings) => CencoriChatLanguageModel;\n}\n\n/**\n * Create a Cencori provider instance\n * \n * @param options - Provider configuration options\n * @returns A Cencori provider\n * \n * @example\n * import { createCencori } from '@cencori/ai-provider';\n * \n * const cencori = createCencori({\n *   apiKey: process.env.CENCORI_API_KEY\n * });\n * \n * const result = await streamText({\n *   model: cencori('gemini-2.5-flash'),\n *   messages: [{ role: 'user', content: 'Hello!' }]\n * });\n */\nexport function createCencori(options: CencoriProviderSettings = {}): CencoriProvider {\n    const baseUrl = options.baseUrl ?? 'https://cencori.com';\n    const apiKey = options.apiKey ?? process.env.CENCORI_API_KEY;\n\n    if (!apiKey) {\n        throw new Error('Cencori API key is required. Pass it via options.apiKey or set CENCORI_API_KEY environment variable.');\n    }\n\n    const createModel = (modelId: string, settings: CencoriChatSettings = {}) => {\n        return new CencoriChatLanguageModel(modelId, {\n            apiKey,\n            baseUrl,\n            headers: options.headers,\n            ...settings,\n        });\n    };\n\n    const provider = function (modelId: string, settings?: CencoriChatSettings) {\n        return createModel(modelId, settings);\n    } as CencoriProvider;\n\n    provider.chat = createModel;\n\n    return provider;\n}\n\n/**\n * Default Cencori provider instance\n * Uses CENCORI_API_KEY environment variable (lazy initialization)\n * \n * @example\n * import { cencori } from '@cencori/ai-provider';\n * import { streamText } from 'ai';\n * \n * const result = await streamText({\n *   model: cencori('gemini-2.5-flash'),\n *   messages: [{ role: 'user', content: 'Hello!' }]\n * });\n */\nexport const cencori: CencoriProvider = function (modelId: string, settings?: CencoriChatSettings) {\n    const apiKey = process.env.CENCORI_API_KEY;\n    if (!apiKey) {\n        throw new Error('CENCORI_API_KEY environment variable is required. Set it or use createCencori({ apiKey: \"...\" }) instead.');\n    }\n    return new CencoriChatLanguageModel(modelId, {\n        apiKey,\n        baseUrl: 'https://cencori.com',\n        ...settings,\n    });\n} as CencoriProvider;\n\ncencori.chat = cencori;\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AC+CO,IAAM,2BAAN,MAA0D;AAAA,EAS7D,YAAY,SAAiB,UAAoC;AARjE,SAAS,uBAAuB;AAChC,SAAS,WAAW;AACpB,SAAS,8BAA8B;AACvC,SAAS,oBAAoB;AAMzB,SAAK,UAAU;AACf,SAAK,WAAW;AAAA,EACpB;AAAA,EAEQ,aAAqC;AACzC,WAAO;AAAA,MACH,gBAAgB;AAAA,MAChB,mBAAmB,KAAK,SAAS;AAAA,MACjC,GAAG,KAAK,SAAS;AAAA,IACrB;AAAA,EACJ;AAAA,EAEQ,gBAAgB,SAAuD;AAC3E,UAAM,WAA6B,CAAC;AAGpC,QAAI,QAAQ,UAAU,OAAO,QAAQ,WAAW,YAAY,YAAY,QAAQ,UAAU,QAAQ,OAAO,QAAQ;AAC7G,eAAS,KAAK,EAAE,MAAM,UAAU,SAAS,QAAQ,OAAO,OAAiB,CAAC;AAAA,IAC9E;AAGA,QAAI,QAAQ,UAAU,OAAO,QAAQ,WAAW,YAAY,cAAc,QAAQ,QAAQ;AACtF,YAAM,iBAAiB,QAAQ,OAAO;AAKtC,iBAAW,OAAO,gBAAgB;AAC9B,YAAI,UAAU;AAEd,YAAI,OAAO,IAAI,YAAY,UAAU;AACjC,oBAAU,IAAI;AAAA,QAClB,WAAW,MAAM,QAAQ,IAAI,OAAO,GAAG;AAEnC,oBAAU,IAAI,QACT,OAAO,CAAC,SAA2B,KAAK,SAAS,MAAM,EACvD,IAAI,CAAC,SAA0C,KAAK,QAAQ,EAAE,EAC9D,KAAK,EAAE;AAAA,QAChB;AAEA,YAAI,SAAS;AACT,mBAAS,KAAK;AAAA,YACV,MAAM,IAAI;AAAA,YACV;AAAA,UACJ,CAAC;AAAA,QACL;AAAA,MACJ;AAAA,IACJ;AAEA,WAAO;AAAA,EACX;AAAA,EAEQ,gBAAgB,QAA8C;AAClE,YAAQ,QAAQ;AAAA,MACZ,KAAK;AAAA,MACL,KAAK;AACD,eAAO;AAAA,MACX,KAAK;AAAA,MACL,KAAK;AACD,eAAO;AAAA,MACX,KAAK;AACD,eAAO;AAAA,MACX,KAAK;AAAA,MACL,KAAK;AACD,eAAO;AAAA,MACX;AACI,eAAO;AAAA,IACf;AAAA,EACJ;AAAA,EAEA,MAAM,WAAW,SAUd;AACC,UAAM,WAAW,KAAK,gBAAgB,OAAO;AAE7C,UAAM,WAAW,MAAM,MAAM,GAAG,KAAK,SAAS,OAAO,gBAAgB;AAAA,MACjE,QAAQ;AAAA,MACR,SAAS,KAAK,WAAW;AAAA,MACzB,MAAM,KAAK,UAAU;AAAA,QACjB;AAAA,QACA,OAAO,KAAK;AAAA,QACZ,aAAa,QAAQ;AAAA,QACrB,WAAW,QAAQ;AAAA,QACnB,QAAQ;AAAA,QACR,QAAQ,KAAK,SAAS;AAAA,MAC1B,CAAC;AAAA,MACD,QAAQ,QAAQ;AAAA,IACpB,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AACd,YAAM,QAAQ,MAAM,SAAS,KAAK,EAAE,MAAM,OAAO,EAAE,OAAO,gBAAgB,EAAE;AAC5E,YAAM,IAAI,MAAM,sBAAsB,MAAM,SAAS,SAAS,UAAU,EAAE;AAAA,IAC9E;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,WAAO;AAAA,MACH,MAAM,KAAK;AAAA,MACX,cAAc,KAAK,gBAAgB,KAAK,aAAa;AAAA,MACrD,OAAO;AAAA,QACH,cAAc,KAAK,MAAM;AAAA,QACzB,kBAAkB,KAAK,MAAM;AAAA,MACjC;AAAA,MACA,SAAS;AAAA,QACL,WAAW;AAAA,QACX,aAAa;AAAA,UACT,OAAO,KAAK;AAAA,UACZ,aAAa,QAAQ;AAAA,UACrB,WAAW,QAAQ;AAAA,QACvB;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,MAAM,SAAS,SAKZ;AACC,UAAM,WAAW,KAAK,gBAAgB,OAAO;AAE7C,UAAM,WAAW,MAAM,MAAM,GAAG,KAAK,SAAS,OAAO,gBAAgB;AAAA,MACjE,QAAQ;AAAA,MACR,SAAS,KAAK,WAAW;AAAA,MACzB,MAAM,KAAK,UAAU;AAAA,QACjB;AAAA,QACA,OAAO,KAAK;AAAA,QACZ,aAAa,QAAQ;AAAA,QACrB,WAAW,QAAQ;AAAA,QACnB,QAAQ;AAAA,QACR,QAAQ,KAAK,SAAS;AAAA,MAC1B,CAAC;AAAA,MACD,QAAQ,QAAQ;AAAA,IACpB,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AACd,YAAM,QAAQ,MAAM,SAAS,KAAK,EAAE,MAAM,OAAO,EAAE,OAAO,gBAAgB,EAAE;AAC5E,YAAM,IAAI,MAAM,sBAAsB,MAAM,SAAS,SAAS,UAAU,EAAE;AAAA,IAC9E;AAEA,UAAM,SAAS,SAAS,MAAM,UAAU;AACxC,QAAI,CAAC,QAAQ;AACT,YAAM,IAAI,MAAM,uBAAuB;AAAA,IAC3C;AAEA,UAAM,UAAU,IAAI,YAAY;AAChC,QAAI,SAAS;AACb,QAAI,eAAe;AACnB,QAAI,mBAAmB;AAEvB,UAAM,SAAS,IAAI,eAA0C;AAAA,MACzD,MAAM,KAAK,YAAY;AACnB,YAAI;AACA,gBAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAE1C,cAAI,MAAM;AAEN,uBAAW,QAAQ;AAAA,cACf,MAAM;AAAA,cACN,cAAc;AAAA,cACd,OAAO,EAAE,cAAc,iBAAiB;AAAA,YAC5C,CAAC;AACD,uBAAW,MAAM;AACjB;AAAA,UACJ;AAEA,oBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,gBAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,mBAAS,MAAM,IAAI,KAAK;AAExB,qBAAW,QAAQ,OAAO;AACtB,gBAAI,KAAK,KAAK,MAAM,GAAI;AACxB,gBAAI,CAAC,KAAK,WAAW,QAAQ,EAAG;AAEhC,kBAAM,OAAO,KAAK,MAAM,CAAC;AACzB,gBAAI,SAAS,UAAU;AACnB,yBAAW,QAAQ;AAAA,gBACf,MAAM;AAAA,gBACN,cAAc;AAAA,gBACd,OAAO,EAAE,cAAc,iBAAiB;AAAA,cAC5C,CAAC;AACD,yBAAW,MAAM;AACjB;AAAA,YACJ;AAEA,gBAAI;AACA,oBAAM,QAAQ,KAAK,MAAM,IAAI;AAE7B,kBAAI,MAAM,OAAO;AACb,oCAAoB,KAAK,KAAK,MAAM,MAAM,SAAS,CAAC;AACpD,2BAAW,QAAQ;AAAA,kBACf,MAAM;AAAA,kBACN,WAAW,MAAM;AAAA,gBACrB,CAAC;AAAA,cACL;AAEA,kBAAI,MAAM,eAAe;AACrB,2BAAW,QAAQ;AAAA,kBACf,MAAM;AAAA,kBACN,cAAc;AAAA,kBACd,OAAO,EAAE,cAAc,iBAAiB;AAAA,gBAC5C,CAAC;AACD,2BAAW,MAAM;AACjB;AAAA,cACJ;AAAA,YACJ,QAAQ;AAAA,YAER;AAAA,UACJ;AAAA,QACJ,SAAS,OAAO;AACZ,qBAAW,MAAM,KAAK;AAAA,QAC1B;AAAA,MACJ;AAAA,MACA,SAAS;AACL,eAAO,OAAO;AAAA,MAClB;AAAA,IACJ,CAAC;AAED,WAAO;AAAA,MACH;AAAA,MACA,SAAS;AAAA,QACL,WAAW;AAAA,QACX,aAAa;AAAA,UACT,OAAO,KAAK;AAAA,UACZ,aAAa,QAAQ;AAAA,UACrB,WAAW,QAAQ;AAAA,QACvB;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AACJ;;;ACpPO,SAAS,cAAc,UAAmC,CAAC,GAAoB;AAClF,QAAM,UAAU,QAAQ,WAAW;AACnC,QAAM,SAAS,QAAQ,UAAU,QAAQ,IAAI;AAE7C,MAAI,CAAC,QAAQ;AACT,UAAM,IAAI,MAAM,sGAAsG;AAAA,EAC1H;AAEA,QAAM,cAAc,CAAC,SAAiB,WAAgC,CAAC,MAAM;AACzE,WAAO,IAAI,yBAAyB,SAAS;AAAA,MACzC;AAAA,MACA;AAAA,MACA,SAAS,QAAQ;AAAA,MACjB,GAAG;AAAA,IACP,CAAC;AAAA,EACL;AAEA,QAAM,WAAW,SAAU,SAAiB,UAAgC;AACxE,WAAO,YAAY,SAAS,QAAQ;AAAA,EACxC;AAEA,WAAS,OAAO;AAEhB,SAAO;AACX;AAeO,IAAM,UAA2B,SAAU,SAAiB,UAAgC;AAC/F,QAAM,SAAS,QAAQ,IAAI;AAC3B,MAAI,CAAC,QAAQ;AACT,UAAM,IAAI,MAAM,2GAA2G;AAAA,EAC/H;AACA,SAAO,IAAI,yBAAyB,SAAS;AAAA,IACzC;AAAA,IACA,SAAS;AAAA,IACT,GAAG;AAAA,EACP,CAAC;AACL;AAEA,QAAQ,OAAO;","names":[]}