import { DoneStreamChunk, ModelMessage, Tool, ToolCall, ToolResultStreamChunk } from '../../../types.js';
/**
 * Manages tool call accumulation and execution for the chat() method's automatic tool execution loop.
 *
 * Responsibilities:
 * - Accumulates streaming tool call chunks (ID, name, arguments)
 * - Validates tool calls (filters out incomplete ones)
 * - Executes tool `execute` functions with parsed arguments
 * - Emits `tool_result` chunks for client visibility
 * - Returns tool result messages for conversation history
 *
 * This class is used internally by the AI.chat() method to handle the automatic
 * tool execution loop. It can also be used independently for custom tool execution logic.
 *
 * @example
 * ```typescript
 * const manager = new ToolCallManager(tools);
 *
 * // During streaming, accumulate tool calls
 * for await (const chunk of stream) {
 *   if (chunk.type === "tool_call") {
 *     manager.addToolCallChunk(chunk);
 *   }
 * }
 *
 * // After stream completes, execute tools
 * if (manager.hasToolCalls()) {
 *   const toolResults = yield* manager.executeTools(doneChunk);
 *   messages = [...messages, ...toolResults];
 *   manager.clear();
 * }
 * ```
 */
export declare class ToolCallManager {
    private toolCallsMap;
    private tools;
    constructor(tools: ReadonlyArray<Tool>);
    /**
     * Add a tool call chunk to the accumulator
     * Handles streaming tool calls by accumulating arguments
     */
    addToolCallChunk(chunk: {
        toolCall: {
            id: string;
            type: 'function';
            function: {
                name: string;
                arguments: string;
            };
        };
        index: number;
    }): void;
    /**
     * Check if there are any complete tool calls to execute
     */
    hasToolCalls(): boolean;
    /**
     * Get all complete tool calls (filtered for valid ID and name)
     */
    getToolCalls(): Array<ToolCall>;
    /**
     * Execute all tool calls and return tool result messages
     * Also yields tool_result chunks for streaming
     */
    executeTools(doneChunk: DoneStreamChunk): AsyncGenerator<ToolResultStreamChunk, Array<ModelMessage>, void>;
    /**
     * Clear the tool calls map for the next iteration
     */
    clear(): void;
}
export interface ToolResult {
    toolCallId: string;
    toolName: string;
    result: any;
    state?: 'output-available' | 'output-error';
    /** Duration of tool execution in milliseconds (only for server-executed tools) */
    duration?: number;
}
export interface ApprovalRequest {
    toolCallId: string;
    toolName: string;
    input: any;
    approvalId: string;
}
export interface ClientToolRequest {
    toolCallId: string;
    toolName: string;
    input: any;
}
interface ExecuteToolCallsResult {
    /** Tool results ready to send to LLM */
    results: Array<ToolResult>;
    /** Tools that need user approval before execution */
    needsApproval: Array<ApprovalRequest>;
    /** Tools that need client-side execution */
    needsClientExecution: Array<ClientToolRequest>;
}
/**
 * Execute tool calls based on their configuration
 *
 * Handles three cases:
 * 1. Client tools (no execute) - request client to execute
 * 2. Server tools with approval - check approval before executing
 * 3. Normal server tools - execute immediately
 *
 * @param toolCalls - Tool calls from the LLM
 * @param tools - Available tools with their configurations
 * @param approvals - Map of approval decisions (approval.id -> approved boolean)
 * @param clientResults - Map of client-side execution results (toolCallId -> result)
 */
export declare function executeToolCalls(toolCalls: Array<ToolCall>, tools: ReadonlyArray<Tool>, approvals?: Map<string, boolean>, clientResults?: Map<string, any>): Promise<ExecuteToolCallsResult>;
export {};
